{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Loss Functions (Lose Me Again).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1vdNUSBazD5lyKSt3pU/k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/actuallyachraf/ai-notebooks/blob/main/Loss_Functions_(Lose_Me_Again).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHQIa0V5PzIb"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5wlJ-ezDNkv"
      },
      "source": [
        "# cross entropy or log loss measures the performance of a classification model\n",
        "# whose output is a probability value in [0,1] (perfect model log_loss = 0)\n",
        "def cross_entropy(yHat,y):\n",
        "  if y == 1:\n",
        "    return -np.log(yHat)\n",
        "  return -np.log(1 - yHat)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwmjl7xKP5tf"
      },
      "source": [
        "# Hinge\n",
        "def hinge(yHat,y):\n",
        "  return np.max(0,1-yHat*y)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BhjrSxaP_Ie"
      },
      "source": [
        "# Huber used for regression\n",
        "def huber(yHat,y,delta=1.):\n",
        "  return np.where(np.abs(y-yHat) < delta, .5*(y-yHat)**2, delta*(np.abs(y-yHat)-0.5*delta))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5J8MAzwQg8C"
      },
      "source": [
        "# Kullback-divergence computes the difference between two probability distributions\n",
        "def kl_divergence(yHat,y):\n",
        "  return np.sum(yHat * np.log((yHat/y)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LlP8QZ-Qrou"
      },
      "source": [
        "# MAE L1\n",
        "def mae_l1(yHat,y):\n",
        "  return np.sum(np.absolute(yHat - y))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwnyg58yQztw"
      },
      "source": [
        "# MSE L2\n",
        "def mse(yHat,y):\n",
        "  return np.sum((yHat-y)**2)/y.size"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcKT_9CeQ6jM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}